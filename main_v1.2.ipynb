{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1.0 2024-04-26\n",
    "1. 把命令行参数修改为适配jupiter模式，增加一个函数，既可以从命令行获取参数，也可以从jupiter中获取参数\n",
    "2. 把整个程序按照jupiter分段，方便调试\n",
    "\n",
    "v1.1 2024-04-28\n",
    "1. 把数据源改为mysql，训练单支股票"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse # v1.0 用来解析命令行参数\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入SQL数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_mysql(ts_code): \n",
    "    print (f\"从数据库里获得股票{ts_code}\")\n",
    "\n",
    "    # 连接 MySQL 数据库\n",
    "    engine = create_engine('mysql+mysqlconnector://root:@localhost/stock_ai')\n",
    "    conn = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='',\n",
    "        database='stock_ai'\n",
    "    )\n",
    "    if conn.is_connected():\n",
    "        print('连接成功！')\n",
    "        cursor = conn.cursor() # 创建一个游标对象来执行SQL语句\n",
    "    \n",
    "        print(\"开始分析：\",f\"股票{ts_code}\");\n",
    "        select_sub_query = f\"SELECT `low`,`pct_chg`, `day_count`, `open`, `high`, `close`, `average`, `average_vs_pre_close`, `change`, `turnover_rate_f`, `volume_ratio`, `winner`, `pe`, `pb`, `ps`, `dv_ratio`, `k`, `d`, `j`, `macd`, `signal_line`, `macd_histogram`, `ma_5`, `ma_10`, `ma_20`, `ma_60`, `ma_120`, `ma_250`, `rsi` FROM `stock_daily_price` WHERE `ts_code` = '{ts_code}' ORDER BY `trade_date` ASC;\"\n",
    "        # 转换为SQLAlchemy的engine对象\n",
    "        engine = create_engine('mysql+mysqlconnector://root:@localhost/stock_ai')\n",
    "        # 从MySQL数据库中读取数据到DataFrame\n",
    "        df = pd.read_sql_query(select_sub_query, con=engine)\n",
    "    \n",
    "    # 关闭连接\n",
    "    conn.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从数据库里获得股票000001\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "2003 (HY000): Can't connect to MySQL server on 'localhost:3306' (10061)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\qdawg\\anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py:327\u001b[0m, in \u001b[0;36mCMySQLConnection._open_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmysql\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcnx_kwargs)\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmysql\u001b[38;5;241m.\u001b[39mconverter_str_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_converter_str_fallback\n",
      "\u001b[1;31mMySQLInterfaceError\u001b[0m: Can't connect to MySQL server on 'localhost:3306' (10061)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong frame seletion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConfig\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# 数据参数\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     feature_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m29\u001b[39m))     \u001b[38;5;66;03m# 要作为feature的列，按原数据从0开始计算，也可以用list 如 [2,4,6,8] 设置\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     label_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]                  \u001b[38;5;66;03m# 要预测的列，按原数据从0开始计算, 如同时预测第四，五列 最低价和最高价\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 65\u001b[0m, in \u001b[0;36mConfig\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m continue_flag \u001b[38;5;241m+\u001b[39m used_frame \u001b[38;5;241m+\u001b[39m model_postfix[used_frame]\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# 路径参数\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# train_data_path = \"./data/stock_data.csv\"\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m train_data_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_from_mysql\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m000001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m model_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./checkpoint/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m used_frame \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     67\u001b[0m figure_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./figure/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m, in \u001b[0;36mget_data_from_mysql\u001b[1;34m(ts_code)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 连接 MySQL 数据库\u001b[39;00m\n\u001b[0;32m      5\u001b[0m engine \u001b[38;5;241m=\u001b[39m create_engine(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmysql+mysqlconnector://root:@localhost/stock_ai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[43mmysql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstock_ai\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_connected():\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m连接成功！\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\qdawg\\anaconda3\\lib\\site-packages\\mysql\\connector\\pooling.py:322\u001b[0m, in \u001b[0;36mconnect\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(ERROR_NO_CEXT)\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CMySQLConnection \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_pure:\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m CMySQLConnection(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m MySQLConnection(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\qdawg\\anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py:144\u001b[0m, in \u001b[0;36mCMySQLConnection.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\qdawg\\anaconda3\\lib\\site-packages\\mysql\\connector\\abstracts.py:1360\u001b[0m, in \u001b[0;36mMySQLConnectionAbstract.connect\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisconnect()\n\u001b[1;32m-> 1360\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1362\u001b[0m charset, collation \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1363\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1364\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1365\u001b[0m )\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m charset \u001b[38;5;129;01mor\u001b[39;00m collation:\n",
      "File \u001b[1;32mc:\\Users\\qdawg\\anaconda3\\lib\\site-packages\\mysql\\connector\\connection_cext.py:332\u001b[0m, in \u001b[0;36mCMySQLConnection._open_connection\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter\u001b[38;5;241m.\u001b[39mstr_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_converter_str_fallback\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MySQLInterfaceError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m get_mysql_exception(\n\u001b[0;32m    333\u001b[0m         msg\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mmsg, errno\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39merrno, sqlstate\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39msqlstate\n\u001b[0;32m    334\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_handshake()\n\u001b[0;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ssl_disabled\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cmysql, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_ssl_cipher\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    345\u001b[0m \n\u001b[0;32m    346\u001b[0m     \u001b[38;5;66;03m# `get_ssl_cipher()` returns the name of the cipher being used.\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: 2003 (HY000): Can't connect to MySQL server on 'localhost:3306' (10061)"
     ]
    }
   ],
   "source": [
    "frame = \"pytorch\"  # 可选： \"keras\", \"pytorch\", \"tensorflow\"\n",
    "if frame == \"pytorch\":\n",
    "    from model.model_pytorch import train, predict\n",
    "elif frame == \"keras\":\n",
    "    from model.model_keras import train, predict\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'\n",
    "elif frame == \"tensorflow\":\n",
    "    from model.model_tensorflow import train, predict\n",
    "    os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'    # tf和keras下会有很多tf的warning，但不影响训练\n",
    "else:\n",
    "    raise Exception(\"Wrong frame seletion\")\n",
    "\n",
    "class Config:\n",
    "    # 数据参数\n",
    "    feature_columns = list(range(0, 29))     # 要作为feature的列，按原数据从0开始计算，也可以用list 如 [2,4,6,8] 设置\n",
    "    label_columns = [0, 1]                  # 要预测的列，按原数据从0开始计算, 如同时预测第四，五列 最低价和最高价\n",
    "    # label_in_feature_index = [feature_columns.index(i) for i in label_columns]  # 这样写不行\n",
    "    label_in_feature_index = (lambda x,y: [x.index(i) for i in y])(feature_columns, label_columns)  # 因为feature不一定从0开始\n",
    "\n",
    "    predict_day = 1             # 预测未来几天\n",
    "\n",
    "    # 网络参数\n",
    "    input_size = len(feature_columns)\n",
    "    output_size = len(label_columns)\n",
    "\n",
    "    hidden_size = 128           # LSTM的隐藏层大小，也是输出大小\n",
    "    lstm_layers = 3             # LSTM的堆叠层数\n",
    "    dropout_rate = 0.2          # dropout概率，示在每次更新时，每个神经元有20%的概率被关闭。防止过度依赖于某个神经元，变成过拟合。\n",
    "    time_step = 30              # 这个参数很重要，是设置用前多少天的数据来预测，也是LSTM的time step数，请保证训练数据量大于它\n",
    "\n",
    "    # 训练参数\n",
    "    do_train = True\n",
    "    do_predict = True\n",
    "    add_train = False           # 是否载入已有模型参数进行增量训练\n",
    "    shuffle_train_data = False   # 是否对训练数据做shuffle，股票的日顺序不应该被打乱。\n",
    "    use_cuda = True            # 是否使用GPU训练\n",
    "\n",
    "    train_data_rate = 0.95      # 训练数据占总体数据比例，测试数据就是 1-train_data_rate\n",
    "    valid_data_rate = 0.15      # 验证数据占训练数据比例，验证集在训练过程使用，为了做模型和参数选择。验证数据是在模型训练过程中用来评估模型性能和调整模型参数的数据，它不参与模型的训练。\n",
    "\n",
    "    batch_size = 64\n",
    "    learning_rate = 0.001\n",
    "    epoch = 20                  # 整个训练集被训练多少遍，不考虑早停的前提下\n",
    "    patience = 5                # 训练多少epoch，验证集没提升就停掉\n",
    "    random_seed = 2024            # 随机种子，保证可复现\n",
    "\n",
    "    do_continue_train = False    # 每次训练把上一次的final_state作为下一次的init_state，仅用于RNN类型模型，目前仅支持pytorch\n",
    "    continue_flag = \"\"           # 但实际效果不佳，可能原因：仅能以 batch_size = 1 训练\n",
    "    if do_continue_train:\n",
    "        shuffle_train_data = False\n",
    "        batch_size = 1\n",
    "        continue_flag = \"continue_\"\n",
    "\n",
    "    # 训练模式\n",
    "    debug_mode = False  # 调试模式下，是为了跑通代码，追求快\n",
    "    debug_num = 500  # 仅用debug_num条数据来调试\n",
    "\n",
    "    # 框架参数\n",
    "    used_frame = frame  # 选择的深度学习框架，不同的框架模型保存后缀不一样\n",
    "    model_postfix = {\"pytorch\": \".pth\", \"keras\": \".h5\", \"tensorflow\": \".ckpt\"}\n",
    "    model_name = \"model_\" + continue_flag + used_frame + model_postfix[used_frame]\n",
    "\n",
    "    # 路径参数\n",
    "    # train_data_path = \"./data/stock_data.csv\"\n",
    "    train_data_path = get_data_from_mysql(\"000001\")\n",
    "    model_save_path = \"./checkpoint/\" + used_frame + \"/\"\n",
    "    figure_save_path = \"./figure/\"\n",
    "    log_save_path = \"./log/\"\n",
    "    do_log_print_to_screen = True\n",
    "    do_log_save_to_file = True                  # 是否将config和训练过程记录到log\n",
    "    do_figure_save = False\n",
    "    do_train_visualized = False          # 训练loss可视化，pytorch用visdom，tf用tensorboardX，实际上可以通用, keras没有\n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)    # makedirs 递归创建目录\n",
    "    if not os.path.exists(figure_save_path):\n",
    "        os.mkdir(figure_save_path)\n",
    "    if do_train and (do_log_save_to_file or do_train_visualized):\n",
    "        cur_time = time.strftime(\"%Y_%m_%d_%H_%M_%S\", time.localtime())\n",
    "        log_save_path = log_save_path + cur_time + '_' + used_frame + \"/\"\n",
    "        os.makedirs(log_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练与测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.data, self.data_column_name = self.read_data() # 这个地方要改成从数据库里读取数据\n",
    "\n",
    "        self.data_num = self.data.shape[0]\n",
    "        self.train_num = int(self.data_num * self.config.train_data_rate)\n",
    "\n",
    "        self.mean = np.mean(self.data, axis=0)              # 数据的均值和方差\n",
    "        self.std = np.std(self.data, axis=0)\n",
    "        self.norm_data = (self.data - self.mean)/self.std   # 归一化，去量纲\n",
    "\n",
    "        self.start_num_in_test = 0      # 测试集中前几天的数据会被删掉，因为它不够一个time_step\n",
    "\n",
    "    def read_data(self):                # 读取初始数据\n",
    "        if self.config.debug_mode:\n",
    "            init_data = get_data_from_mysql(\"000001\").head(self.config.debug_num)\n",
    "        else:\n",
    "            init_data = get_data_from_mysql(\"000001\")\n",
    "        return init_data.values, init_data.columns.tolist()     # .columns.tolist() 是获取列名\n",
    "\n",
    "    \"\"\"\n",
    "    def read_data(self):                # 读取初始数据\n",
    "        if self.config.debug_mode:\n",
    "            init_data = pd.read_csv(self.config.train_data_path, nrows=self.config.debug_num,\n",
    "                                    usecols=self.config.feature_columns)\n",
    "        else:\n",
    "            init_data = pd.read_csv(self.config.train_data_path, usecols=self.config.feature_columns)\n",
    "        return init_data.values, init_data.columns.tolist()     # .columns.tolist() 是获取列名\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def get_train_and_valid_data(self):\n",
    "        feature_data = self.norm_data[:self.train_num]\n",
    "        label_data = self.norm_data[self.config.predict_day : self.config.predict_day + self.train_num,\n",
    "                                    self.config.label_in_feature_index]    # 将延后几天的数据作为label\n",
    "\n",
    "        if not self.config.do_continue_train:\n",
    "            # 在非连续训练模式下，每time_step行数据会作为一个样本，两个样本错开一行，比如：1-20行，2-21行。。。。\n",
    "            train_x = [feature_data[i:i+self.config.time_step] for i in range(self.train_num-self.config.time_step)]\n",
    "            train_y = [label_data[i:i+self.config.time_step] for i in range(self.train_num-self.config.time_step)]\n",
    "        else:\n",
    "            # 在连续训练模式下，每time_step行数据会作为一个样本，两个样本错开time_step行，\n",
    "            # 比如：1-20行，21-40行。。。到数据末尾，然后又是 2-21行，22-41行。。。到数据末尾，……\n",
    "            # 这样才可以把上一个样本的final_state作为下一个样本的init_state，而且不能shuffle\n",
    "            # 目前本项目中仅能在pytorch的RNN系列模型中用\n",
    "            train_x = [feature_data[start_index + i*self.config.time_step : start_index + (i+1)*self.config.time_step]\n",
    "                       for start_index in range(self.config.time_step)\n",
    "                       for i in range((self.train_num - start_index) // self.config.time_step)]\n",
    "            train_y = [label_data[start_index + i*self.config.time_step : start_index + (i+1)*self.config.time_step]\n",
    "                       for start_index in range(self.config.time_step)\n",
    "                       for i in range((self.train_num - start_index) // self.config.time_step)]\n",
    "\n",
    "        train_x, train_y = np.array(train_x), np.array(train_y)\n",
    "\n",
    "        train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=self.config.valid_data_rate,\n",
    "                                                              random_state=self.config.random_seed,\n",
    "                                                              shuffle=self.config.shuffle_train_data)   # 划分训练和验证集，并打乱\n",
    "        return train_x, valid_x, train_y, valid_y\n",
    "\n",
    "    def get_test_data(self, return_label_data=False):\n",
    "        feature_data = self.norm_data[self.train_num:]\n",
    "        sample_interval = min(feature_data.shape[0], self.config.time_step)     # 防止time_step大于测试集数量\n",
    "        self.start_num_in_test = feature_data.shape[0] % sample_interval  # 这些天的数据不够一个sample_interval\n",
    "        time_step_size = feature_data.shape[0] // sample_interval\n",
    "\n",
    "        # 在测试数据中，每time_step行数据会作为一个样本，两个样本错开time_step行\n",
    "        # 比如：1-20行，21-40行。。。到数据末尾。\n",
    "        test_x = [feature_data[self.start_num_in_test+i*sample_interval : self.start_num_in_test+(i+1)*sample_interval]\n",
    "                   for i in range(time_step_size)]\n",
    "        if return_label_data:       # 实际应用中的测试集是没有label数据的\n",
    "            label_data = self.norm_data[self.train_num + self.start_num_in_test:, self.config.label_in_feature_index]\n",
    "            return np.array(test_x), label_data\n",
    "        return np.array(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 记录log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_logger(config):\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(level=logging.DEBUG)\n",
    "\n",
    "    # StreamHandler\n",
    "    if config.do_log_print_to_screen:\n",
    "        stream_handler = logging.StreamHandler(sys.stdout)\n",
    "        stream_handler.setLevel(level=logging.INFO)\n",
    "        formatter = logging.Formatter(datefmt='%Y/%m/%d %H:%M:%S',\n",
    "                                      fmt='[ %(asctime)s ] %(message)s')\n",
    "        stream_handler.setFormatter(formatter)\n",
    "        logger.addHandler(stream_handler)\n",
    "\n",
    "    # FileHandler\n",
    "    if config.do_log_save_to_file:\n",
    "        file_handler = RotatingFileHandler(config.log_save_path + \"out.log\", maxBytes=1024000, backupCount=5)\n",
    "        file_handler.setLevel(level=logging.INFO)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "        # 把config信息也记录到log 文件中\n",
    "        config_dict = {}\n",
    "        for key in dir(config):\n",
    "            if not key.startswith(\"_\"):\n",
    "                config_dict[key] = getattr(config, key)\n",
    "        config_str = str(config_dict)\n",
    "        config_list = config_str[1:-1].split(\", '\")\n",
    "        config_save_str = \"\\nConfig:\\n\" + \"\\n'\".join(config_list)\n",
    "        logger.info(config_save_str)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算结果绘图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(config: Config, origin_data: Data, logger, predict_norm_data: np.ndarray):\n",
    "    label_data = origin_data.data[origin_data.train_num + origin_data.start_num_in_test : ,\n",
    "                                            config.label_in_feature_index]\n",
    "    predict_data = predict_norm_data * origin_data.std[config.label_in_feature_index] + \\\n",
    "                   origin_data.mean[config.label_in_feature_index]   # 通过保存的均值和方差还原数据\n",
    "    assert label_data.shape[0]==predict_data.shape[0], \"The element number in origin and predicted data is different\"\n",
    "\n",
    "    label_name = [origin_data.data_column_name[i] for i in config.label_in_feature_index]\n",
    "    label_column_num = len(config.label_columns)\n",
    "\n",
    "    # label 和 predict 是错开config.predict_day天的数据的\n",
    "    # 下面是两种norm后的loss的计算方式，结果是一样的，可以简单手推一下\n",
    "    # label_norm_data = origin_data.norm_data[origin_data.train_num + origin_data.start_num_in_test:,\n",
    "    #              config.label_in_feature_index]\n",
    "    # loss_norm = np.mean((label_norm_data[config.predict_day:] - predict_norm_data[:-config.predict_day]) ** 2, axis=0)\n",
    "    # logger.info(\"The mean squared error of stock {} is \".format(label_name) + str(loss_norm))\n",
    "\n",
    "    loss = np.mean((label_data[config.predict_day:] - predict_data[:-config.predict_day] ) ** 2, axis=0)\n",
    "    loss_norm = loss/(origin_data.std[config.label_in_feature_index] ** 2)\n",
    "    logger.info(\"The mean squared error of stock {} is \".format(label_name) + str(loss_norm))\n",
    "\n",
    "    label_X = range(origin_data.data_num - origin_data.train_num - origin_data.start_num_in_test)\n",
    "    predict_X = [ x + config.predict_day for x in label_X]\n",
    "\n",
    "    if not sys.platform.startswith('linux'):    # 无桌面的Linux下无法输出，如果是有桌面的Linux，如Ubuntu，可去掉这一行\n",
    "        for i in range(label_column_num):\n",
    "            plt.figure(i+1)                     # 预测数据绘制\n",
    "            plt.plot(label_X, label_data[:, i], label='label')\n",
    "            plt.plot(predict_X, predict_data[:, i], label='predict')\n",
    "            plt.title(\"Predict stock {} price with {}\".format(label_name[i], config.used_frame))\n",
    "            logger.info(\"The predicted stock {} for the next {} day(s) is: \".format(label_name[i], config.predict_day) +\n",
    "                  str(np.squeeze(predict_data[-config.predict_day:, i])))\n",
    "            if config.do_figure_save:\n",
    "                plt.savefig(config.figure_save_path+\"{}predict_{}_with_{}.png\".format(config.continue_flag, label_name[i], config.used_frame))\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 41\u001b[0m\n\u001b[0;32m     32\u001b[0m parser \u001b[38;5;241m=\u001b[39m argparse\u001b[38;5;241m.\u001b[39mArgumentParser()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# parser.add_argument(\"-t\", \"--do_train\", default=False, type=bool, help=\"whether to train\")\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# parser.add_argument(\"-p\", \"--do_predict\", default=True, type=bool, help=\"whether to train\")\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# parser.add_argument(\"-b\", \"--batch_size\", default=64, type=int, help=\"batch size\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# stock_list = [\"000001\", \"000002\"]\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# 读取CSV文件\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./config/stock_list.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m stock_list \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstockcode\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# 循环\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "def get_args(): # v1.0 自己写的函数，用来判断是否在notebook环境或者命令行环境，两者获取参数的方式不同。\n",
    "    parser = argparse.ArgumentParser()\n",
    "    if any(\"jupyter\" in arg for arg in sys.argv):\n",
    "        # 如果在Jupyter notebook中运行，手动设置参数\n",
    "        args = parser.parse_args(args=[])\n",
    "    else:\n",
    "        # 如果在命令行中运行，从命令行获取参数\n",
    "        args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def main(config):\n",
    "    logger = load_logger(config)\n",
    "    try:\n",
    "        np.random.seed(config.random_seed)  # 设置随机种子，保证可复现\n",
    "        data_gainer = Data(config)\n",
    "\n",
    "        if config.do_train:\n",
    "            train_X, valid_X, train_Y, valid_Y = data_gainer.get_train_and_valid_data()\n",
    "            train(config, logger, [train_X, train_Y, valid_X, valid_Y])\n",
    "\n",
    "        if config.do_predict:\n",
    "            test_X, test_Y = data_gainer.get_test_data(return_label_data=True)\n",
    "            pred_result = predict(config, test_X)       # 这里输出的是未还原的归一化预测数据\n",
    "            draw(config, data_gainer, logger, pred_result)\n",
    "    except Exception:\n",
    "        logger.error(\"Run Error\", exc_info=True)\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    import argparse\n",
    "    # argparse方便于命令行下输入参数，可以根据需要增加更多\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"-t\", \"--do_train\", default=False, type=bool, help=\"whether to train\")\n",
    "    # parser.add_argument(\"-p\", \"--do_predict\", default=True, type=bool, help=\"whether to train\")\n",
    "    # parser.add_argument(\"-b\", \"--batch_size\", default=64, type=int, help=\"batch size\")\n",
    "    # parser.add_argument(\"-e\", \"--epoch\", default=20, type=int, help=\"epochs num\")\n",
    "    \n",
    "    \n",
    "    # stock_list = [\"000001\", \"000002\"]\n",
    "    # 读取CSV文件\n",
    "    df = pd.read_csv('./config/stock_list.csv')\n",
    "    stock_list = df['stockcode'].tolist()\n",
    "    # 循环\n",
    "    for stock in stock_list:\n",
    "        con = Config()\n",
    "        # config.train_data_path = file\n",
    "        con.train_data_path = get_data_from_mysql(stock)\n",
    "        for key in dir(args):               # dir(args) 函数获得args所有的属性\n",
    "            if not key.startswith(\"_\"):     # 去掉 args 自带属性，比如__name__等\n",
    "                setattr(con, key, getattr(args, key))   # 将属性值赋给Config\n",
    "        main(con)\n",
    "\n",
    "    #   这种方式可能因为config_list过大导致很慢，省略掉config_list\n",
    "    # config_list = []\n",
    "    # stock_list = [\"000001\", \"000002\"]\n",
    "    # for stock in stock_list:\n",
    "    #     con = Config()\n",
    "    #     # config.train_data_path = file\n",
    "    #     con.train_data_path = get_data_from_mysql(\"000001\")\n",
    "    #     config_list.append(con)\n",
    "        \n",
    "    # for con in config_list:\n",
    "    #     for key in dir(args):               # dir(args) 函数获得args所有的属性\n",
    "    #         if not key.startswith(\"_\"):     # 去掉 args 自带属性，比如__name__等\n",
    "    #             setattr(con, key, getattr(args, key))   # 将属性值赋给Config\n",
    "    #     main(con)\n",
    "\n",
    "    # # args = parser.parse_args() v1.0 删除用下面代替\n",
    "    # args = get_args()\n",
    "\n",
    "    # con = Config()\n",
    "    # for key in dir(args):               # dir(args) 函数获得args所有的属性\n",
    "    #     if not key.startswith(\"_\"):     # 去掉 args 自带属性，比如__name__等\n",
    "    #         setattr(con, key, getattr(args, key))   # 将属性值赋给Config\n",
    "\n",
    "    # main(con)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
